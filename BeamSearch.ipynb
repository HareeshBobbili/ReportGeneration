{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BeamSearch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbzyXiu2OxtU"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import random as rn\r\n",
        "import math \r\n",
        "from PIL import Image, ImageDraw \r\n",
        "from PIL import ImagePath\r\n",
        "from skimage.transform import resize\r\n",
        "from numpy import array\r\n",
        "from numpy import asarray\r\n",
        "from numpy import zeros\r\n",
        "from tensorflow.keras.applications.densenet import DenseNet121\r\n",
        "from tensorflow.keras.applications.densenet import preprocess_input\r\n",
        "from keras.preprocessing.text import one_hot\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.layers import Dense, LSTM, Input, Embedding, Conv2D, Concatenate, Flatten, Add, Dropout\r\n",
        "from nltk.translate.bleu_score import sentence_bleu\r\n",
        "import random\r\n",
        "import pickle\r\n",
        "import os\r\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LylpxP_RAhb",
        "outputId": "d1987bfd-df39-4302-918b-c411bb41362d"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "%cd /content/drive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDOEFzendF47"
      },
      "source": [
        "file = open('/content/drive/My Drive/CS2/features_enc_2048.pickle','rb')\r\n",
        "features = pickle.load(file)\r\n",
        "file.close()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joajKAKuc9ZT"
      },
      "source": [
        "**Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jh0GJVBRfkZ",
        "outputId": "13cd908f-d626-4057-8a28-1bae9fb9285a"
      },
      "source": [
        "token = Tokenizer()\r\n",
        "\r\n",
        "token.fit_on_texts(features['y_vals'])\r\n",
        "vocab_size = len(token.word_index) + 1\r\n",
        "#text_to_sequence method will convert report into vector\r\n",
        "encoded_findings_train = token.texts_to_sequences(features['y_vals'])\r\n",
        "max_length = np.max([len(li) for li in encoded_findings_train])\r\n",
        "print(vocab_size,max_length)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1663 167\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3h0bODOwRj3E"
      },
      "source": [
        "embeddings_index = dict()\r\n",
        "f = open('/content/drive/My Drive/CS2/glove.6B.100d.txt')\r\n",
        "for line in f:\r\n",
        "\tvalues = line.split()\r\n",
        "\tword = values[0]\r\n",
        "\tcoefs = asarray(values[1:], dtype='float32')\r\n",
        "\tembeddings_index[word] = coefs\r\n",
        "f.close()\r\n",
        "\r\n",
        "#Weight Matrix we will use this weights in embedding layer\r\n",
        "embedding_matrix = zeros((vocab_size, 100))\r\n",
        "for word, i in token.word_index.items():\r\n",
        "\tembedding_vector = embeddings_index.get(word)\r\n",
        "\tif embedding_vector is not None:\r\n",
        "\t\tembedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHfiIKQlc4AW"
      },
      "source": [
        "**Encoder-Decoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vC1Qj1LO_fi",
        "outputId": "215ea133-2cf6-4287-f31c-5706632f8de0"
      },
      "source": [
        "os.environ['PYTHONHASHSEED'] = '0'\r\n",
        "\r\n",
        "tf.keras.backend.clear_session()\r\n",
        "\r\n",
        "#random seed values to regenerate the model.\r\n",
        "np.random.seed(0)\r\n",
        "rn.seed(0)\r\n",
        "\r\n",
        "#Image input Layer\r\n",
        "input_image = Input(shape=(2048,), name='Image')\r\n",
        "dense_image = Dense(256, kernel_initializer=tf.keras.initializers.glorot_uniform, name='dense_image')(input_image)\r\n",
        "\r\n",
        "#Text input layer\r\n",
        "input_text = Input(shape=(167,), name='Text')\r\n",
        "Embedding_layer = Embedding(input_dim = 1663, output_dim = 100, input_length=167, mask_zero=True, trainable=False, \r\n",
        "                weights=[embedding_matrix], name=\"Embedding_layer\")\r\n",
        "emb_layer = Embedding_layer(input_text)\r\n",
        "\r\n",
        "#LSTM layer\r\n",
        "lstm_layer = LSTM(units=256, activation='tanh', recurrent_activation='sigmoid', use_bias=True,kernel_initializer=tf.keras.initializers.glorot_uniform,recurrent_initializer=tf.keras.initializers.orthogonal,\r\n",
        "            bias_initializer=tf.keras.initializers.zeros(), return_sequences=True, name=\"lstm_layer\")(emb_layer)\r\n",
        "\r\n",
        "lstm_layer_1 = LSTM(units=256, activation='tanh', recurrent_activation='sigmoid', use_bias=True,kernel_initializer=tf.keras.initializers.glorot_uniform,recurrent_initializer=tf.keras.initializers.orthogonal,\r\n",
        "            bias_initializer=tf.keras.initializers.zeros(), name=\"lstm_layer_1\")\r\n",
        "lstm_layer_1_output = lstm_layer_1(lstm_layer)\r\n",
        "#Droput \r\n",
        "dropout_layer = Dropout(0.4, name='dropout_layer')(lstm_layer_1_output)\r\n",
        "\r\n",
        "add_layer =  tf.keras.layers.Add()([dense_image, dropout_layer])\r\n",
        "\r\n",
        "#Fully connected layer\r\n",
        "fully_connected = Dense(256, activation='relu', kernel_initializer=tf.keras.initializers.he_normal, name='fully_connected')\r\n",
        "fc1_output = fully_connected(add_layer)\r\n",
        "\r\n",
        "dropout_layer_1 = Dropout(0.3, name='dropout_layer_1')(fc1_output)\r\n",
        "output_layer = Dense(vocab_size, activation='softmax', name='Output_layer')\r\n",
        "output = output_layer(dropout_layer_1)\r\n",
        "\r\n",
        "#Final Model\r\n",
        "encoder_decoder = Model(inputs = [input_image, input_text], outputs = output)\r\n",
        "encoder_decoder.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Text (InputLayer)               [(None, 167)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Embedding_layer (Embedding)     (None, 167, 100)     166300      Text[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "lstm_layer (LSTM)               (None, 167, 256)     365568      Embedding_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "Image (InputLayer)              [(None, 2048)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_layer_1 (LSTM)             (None, 256)          525312      lstm_layer[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_image (Dense)             (None, 256)          524544      Image[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_layer (Dropout)         (None, 256)          0           lstm_layer_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 256)          0           dense_image[0][0]                \n",
            "                                                                 dropout_layer[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "fully_connected (Dense)         (None, 256)          65792       add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_layer_1 (Dropout)       (None, 256)          0           fully_connected[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "Output_layer (Dense)            (None, 1663)         427391      dropout_layer_1[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 2,074,907\n",
            "Trainable params: 1,908,607\n",
            "Non-trainable params: 166,300\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_b7Z3kndcy3b"
      },
      "source": [
        "**Loading Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_fR9eenR_SP"
      },
      "source": [
        "encoder_decoder.load_weights('/content/drive/My Drive/CS2/save_model.h5')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lA4wBIiP9ZXA"
      },
      "source": [
        "**Greedy Search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NORWiBn9d3R"
      },
      "source": [
        "def greedySearch(image_vec):\r\n",
        "  #In the first time step we provide the start token so that the decoder starts generating the next token.\r\n",
        "  report = 'start'\r\n",
        "  for index in range(max_length):\r\n",
        "    input_token = [token.word_index[word] for word in report.split()]\r\n",
        "    input_padded = pad_sequences([input_token], maxlen=max_length)\r\n",
        "    prediction = encoder_decoder.predict([image_vec,input_padded], verbose=0)\r\n",
        "    #greedily select the word with maximum probability\r\n",
        "    #selects the most likely word at each step in the output sequence\r\n",
        "    prediction = np.argmax(prediction)\r\n",
        "    word = token.index_word[prediction]\r\n",
        "    report += ' ' + word\r\n",
        "    if word == 'end':\r\n",
        "      break\r\n",
        "  \r\n",
        "  finding = report.split()[1:-1]\r\n",
        "  return ' '.join(finding)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOoNAmeCchIQ"
      },
      "source": [
        "**Beam Search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4lhwrX0U57Y"
      },
      "source": [
        "def beamsearch(img_features, beam_width_param):\r\n",
        "  #Converting start word into integer array using tokenizer which is trained on findings\r\n",
        "  start_word = [token.word_index['start']]\r\n",
        "  #Sequence contains report array and score.  Here 0.0 is a score.\r\n",
        "  sequences = [[start_word, 0.0]]\r\n",
        "  final_sequence = []\r\n",
        "\r\n",
        "  for index in range(max_length):\r\n",
        "    candidate_array = []\r\n",
        "    seq_array = []\r\n",
        "    #Iterate over each step in sequence\r\n",
        "    #At each step, each candidate sequence is expanded with all possible next steps.\r\n",
        "    for step in sequences:\r\n",
        "      input_sentence = pad_sequences([step[0]], max_length, padding='post')\r\n",
        "      predictions = encoder_decoder.predict([img_features,input_sentence],verbose=0)\r\n",
        "      beam_width_words = np.argsort(predictions[0])[-beam_width_param:]\r\n",
        "      seq, score = step\r\n",
        "      #Iterate over top n beam width words \r\n",
        "      #Using Conditional probability(Each candidate step is scored by multiplying the probabilities together)\r\n",
        "      for word in beam_width_words:\r\n",
        "        #To avoid underflowing the floating point numbers, the natural logarithm of the probabilities are added together\r\n",
        "        candidates = [seq + [word], score - np.log(predictions[0][word])]\r\n",
        "        candidate_array.append(candidates)\r\n",
        "    #sort all candidate sequences in ascending order by their score and select the first k(bean width param) as the most likely candidate sequences            \r\n",
        "    sequences = sorted(candidate_array, key = lambda val: val[1])[:beam_width_param]\r\n",
        "\r\n",
        "    count = 0\r\n",
        "    #Iterate over expanded sequences in each step, if sequence contains 'end' add it to final array otherwise give that sequnce as a input to next step\r\n",
        "    for seq,score in sequences:\r\n",
        "      #If report contains final word as end add it to final sequence array.we use this array as our final report. it contains K((bean width param)) no of arrays.\r\n",
        "      if seq[len(seq)-1] == token.word_index['end']:\r\n",
        "        score = score/len(seq)\r\n",
        "        final_sequence.append([seq, score])\r\n",
        "        count+=1\r\n",
        "      else:\r\n",
        "        seq_array.append([seq, score])\r\n",
        "    beam_width_param -= count\r\n",
        "    \r\n",
        "    #Break loop if length of seq_array is zero.here zero length means sequence reaches end.\r\n",
        "    if len(seq_array)!=0:\r\n",
        "      sequences = seq_array\r\n",
        "    else:\r\n",
        "      break\r\n",
        "\r\n",
        "  #From final_sequence array we have to pick last index value because it contains actual report.\r\n",
        "  sequences = final_sequence[-1] \r\n",
        "  report = sequences[0][1:len(sequences[0])-1]\r\n",
        "  \r\n",
        "  #Returning report and score\r\n",
        "  return ' '.join(token.index_word[word] for word in report), sequences[1]\r\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "na4ZgwBmTZTb"
      },
      "source": [
        "**Prediction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ct7FnbiZIR8s"
      },
      "source": [
        "**Report - 67**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "ed0RhojI-SQJ",
        "outputId": "d28f0a4f-3b05-4b33-f8ea-b3d79a01eed8"
      },
      "source": [
        "features['y_test'][67]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'start the heart pulmonary and mediastinum are within normal limits there is no pleural effusion or pneumothora there is no focal air space opacity to suggest a pneumonia there are mild degenerative changes of the spine end'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "higJrumW-P6m",
        "outputId": "9b797dcc-78e6-4295-e260-6504528ba271"
      },
      "source": [
        "greedySearch(features['image_test'][67])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'the heart pulmonary and mediastinum are within normal limits is no pleural effusion or pneumothora there is no focal air opacity to suggest a pneumonia of the spine'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOVtZYxX-fQ7",
        "outputId": "1ce30b42-0952-4521-f322-f2e491c65dd3"
      },
      "source": [
        "beamsearch(features['image_test'][67],3)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('the heart pulmonary and mediastinum are within normal limits there no pleural effusion or pneumothora there no focal air space to suggest pneumonia mild changes of spine',\n",
            "0.1782400974189031)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADPZNVcH_SxT",
        "outputId": "627f543d-1de5-4f53-f20a-eab6d1fe38b9"
      },
      "source": [
        "beamsearch(features['image_test'][67],5)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('the heart pulmonary and mediastinum are within normal limits there no pleural effusion or pneumothora there no focal air opacity to suggest pneumonia mild changes spine is unremarkable',\n",
            "0.183694479797972)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-8QZ5w-IX4d"
      },
      "source": [
        "**Report-85**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "mBHLkr5MeemY",
        "outputId": "86bfd707-1c99-42ea-d42f-5d11f3912649"
      },
      "source": [
        "features['y_test'][85]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'start the cardiomediastinal silhouette is normal in size and contour hyperepanded lungs without focal consolidation pneumothora or large pleural effusion right chest wall surgical clips compatible with prior lumpectomy negative for acute bone abnormality end'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQ7bM9ECJWla",
        "outputId": "da38a305-6a06-4628-e9e8-1924d9e9f0a1"
      },
      "source": [
        "greedySearch(features['image_test'][85])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'the cardiomediastinal silhouette is normal size contour hyperepanded lungs focal pneumothora or pleural effusion right chest wall surgical prior lumpectomy'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7NMrvsLKdZ-",
        "outputId": "2d082d7e-3383-409a-ca48-019da521fea8"
      },
      "source": [
        "beamsearch(features['image_test'][85],3)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('the cardiomediastinal silhouette is normal size and contour lungs without focal pneumothora or pleural effusion right chest clips compatible lumpectomy negative acute bone',\n",
            "0.17056136571959541)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LI7ZJGzFRS4s",
        "outputId": "09ad8736-4107-4af3-c08f-02b7c3ea933e"
      },
      "source": [
        "beamsearch(features['image_test'][85],5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('the cardiomediastinal silhouette is normal size and contour lungs without focal pneumothora or pleural effusion cardio right chest wall clips is lumpectomy negative for without acute abnormality specifically',\n",
            "0.18776584005461245)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAekYMH7Nbk1"
      },
      "source": [
        "**Report-128**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "aHi7KxhuNaUO",
        "outputId": "9c7264b9-e5da-45e7-bd22-6ba74ce72135"
      },
      "source": [
        "features['y_test'][128]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'start cardiomediastinal silhouette is within normal limits of size and appearance the pulmonary vascularity is unremarkable there are opacities in the left subsegmental atelectasis or scar otherwise the lungs are epanded and clear of airspace disease negative for pneumothora or pleural effusion limited bone evaluation reveals no acute abnormality end'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJOIOrx6NnYz",
        "outputId": "8cd56a31-38ec-4350-8afb-cbfae8a7eb84"
      },
      "source": [
        "greedySearch(features['image_test'][128])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'cardiomediastinal silhouette is normal size and appearance pulmonary vascularity is unremarkable opacities in left subsegmental atelectasis lungs clear for pneumothora or pleural effusion'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U78UaAUzQBeN",
        "outputId": "f5c643f1-6c7b-4303-e97b-874c1fca8a1c"
      },
      "source": [
        "beamsearch(features['image_test'][128],3)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('cardiomediastinal silhouette is normal size and appearance the pulmonary vascularity is unremarkable there opacities in left subsegmental atelectasis the lungs are epanded airspace disease pneumothora or pleural effusion no acute abnormality',\n",
            "0.1796071334771966)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvPD-Qh4Rng7",
        "outputId": "0b5ea1e5-bdac-4902-f04c-f90c4a494bec"
      },
      "source": [
        "beamsearch(features['image_test'][128],5)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('cardiomediastinal silhouette is within limits of size and appearance pulmonary vascularity is unremarkable there are opacities in left subsegmental atelectasis otherwise lungs are airspace disease for pneumothora or pleural effusion limited bone acute abnormality',\n",
            "0.2031660586232448)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}